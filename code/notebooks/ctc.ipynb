{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.cross_validation import StratifiedKFold, KFold, train_test_split\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers.core import Dense, Activation, Merge, Dropout\n",
    "from keras.layers import LSTM, Input, Lambda\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from utilities.utils import *\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "nb_feat = 34\n",
    "nb_class = 4\n",
    "nb_epoch = 2\n",
    "\n",
    "optimizer = 'Adadelta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "available_emotions            ['ang' 'exc' 'neu' 'sad']                                             \n",
      "conf_matrix_prefix            iemocap                                                               \n",
      "framerate                     16000                                                                 \n",
      "path_to_data                  /root/shared/Documents/emotion_recognition/code/utilities/../../data/s\n",
      "path_to_features              /root/shared/Documents/emotion_recognition/code/utilities/../../data/f\n",
      "path_to_features_yaafe        /root/shared/Documents/emotion_recognition/code/utilities/../../data/y\n",
      "path_to_yaafe                 /root/shared/Documents/emotion_recognition/code/utilities/../../data/y\n",
      "sessions                      ['Session1', 'Session2', 'Session3', 'Session4', 'Session5']          \n",
      "types                         {1: <type 'numpy.int8'>, 2: <type 'numpy.int16'>, 4: <type 'numpy.int3\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "params = Constants()\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = read_iemocap_data(params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4900, ' out of ', 4936)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(208603, 14336)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_features(data, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    shift = 2\n",
    "    y_pred = y_pred[:, shift:, :]\n",
    "    input_length -= shift\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_model(nb_feat, nb_class, optimizer='Adadelta'):\n",
    "    net_input = Input(name=\"the_input\", shape=(78, nb_feat))\n",
    "    forward_lstm1  = LSTM(output_dim=64, \n",
    "                          return_sequences=True, \n",
    "                          activation=\"tanh\"\n",
    "                         )(net_input)\n",
    "    backward_lstm1 = LSTM(output_dim=64, \n",
    "                          return_sequences=True, \n",
    "                          activation=\"tanh\",\n",
    "                          go_backwards=True\n",
    "                         )(net_input)\n",
    "    blstm_output1  = Merge(mode='concat')([forward_lstm1, backward_lstm1])\n",
    "\n",
    "    forward_lstm2  = LSTM(output_dim=64, \n",
    "                          return_sequences=True, \n",
    "                          activation=\"tanh\"\n",
    "                         )(blstm_output1)\n",
    "    backward_lstm2 = LSTM(output_dim=64, \n",
    "                          return_sequences=True, \n",
    "                          activation=\"tanh\",\n",
    "                          go_backwards=True\n",
    "                         )(blstm_output1)\n",
    "    blstm_output2  = Merge(mode='concat')([forward_lstm2, backward_lstm2])\n",
    "\n",
    "    hidden = TimeDistributed(Dense(512, activation='tanh'))(blstm_output2)\n",
    "    output = TimeDistributed(Dense(nb_class + 1, activation='softmax'))(hidden)\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[1], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name=\"ctc\")([output, labels, input_length, label_length])\n",
    "\n",
    "    model = Model(input=[net_input, labels, input_length, label_length], output=[loss_out])\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=optimizer, metrics=[])\n",
    "\n",
    "    test_func = K.function([net_input], [output])\n",
    "    \n",
    "    return model, test_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python2.7/site-packages/keras/engine/topology.py:368: UserWarning: The `regularizers` property of layers/models is deprecated. Regularization losses are now managed via the `losses` layer/model property.\n",
      "  warnings.warn('The `regularizers` property of '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "the_input (InputLayer)           (None, 78, 34)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 78, 64)        25344       the_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 78, 64)        25344       the_input[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 78, 128)       0           lstm_1[0][0]                     \n",
      "                                                                   lstm_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                    (None, 78, 64)        49408       merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                    (None, 78, 64)        49408       merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "merge_2 (Merge)                  (None, 78, 128)       0           lstm_3[0][0]                     \n",
      "                                                                   lstm_4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_1 (TimeDistribut (None, 78, 512)       66048       merge_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_2 (TimeDistribut (None, 78, 5)         2565        timedistributed_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "the_labels (InputLayer)          (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_length (InputLayer)        (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "label_length (InputLayer)        (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "ctc (Lambda)                     (None, 1)             0           timedistributed_2[0][0]          \n",
      "                                                                   the_labels[0][0]                 \n",
      "                                                                   input_length[0][0]               \n",
      "                                                                   label_length[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 218,117\n",
      "Trainable params: 218,117\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model, test_func = build_model(nb_feat=nb_feat, nb_class=nb_class, optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y, valid_idxs = get_sample(ids=None, take_all=True)\n",
    "y = np.argmax(to_categorical(y, params), axis=1)\n",
    "y = np.reshape(y, (y.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, X_mask = pad_sequence_into_array(X, maxlen=78)\n",
    "y, y_mask = pad_sequence_into_array(y, maxlen=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index_to_retain = np.sum(X_mask, axis=1, dtype=np.int32) > 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, X_mask = X[index_to_retain], X_mask[index_to_retain]\n",
    "y, y_mask = y[index_to_retain], y_mask[index_to_retain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idxs_train, idxs_test = train_test_split(range(X.shape[0]))\n",
    "X_train, X_test = X[idxs_train], X[idxs_test]\n",
    "X_train_mask, X_test_mask = X_mask[idxs_train], X_mask[idxs_test]\n",
    "y_train, y_test = y[idxs_train], y[idxs_test]\n",
    "y_train_mask, y_test_mask = y_mask[idxs_train], y_mask[idxs_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_weights = np.unique(y, return_counts=True)[1]*1.\n",
    "class_weights = np.sum(class_weights) / class_weights\n",
    "\n",
    "sample_weight = np.zeros(y_train.shape[0])\n",
    "for num, i in enumerate(y_train):\n",
    "    sample_weight[num] = class_weights[i[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1, WA Tr = 0.00, UA Tr = 0.00, WA Te = 0.00, UA Te = 0.00, CTC Tr = 16.94, CTC Te = 2.27, time = 0.81mins\n",
      "epoch = 2, WA Tr = 0.00, UA Tr = 0.00, WA Te = 0.00, UA Te = 0.00, CTC Tr = 8.88, CTC Te = 2.14, time = 0.66mins\n"
     ]
    }
   ],
   "source": [
    "ua_train = np.zeros(nb_epoch)\n",
    "ua_test = np.zeros(nb_epoch)\n",
    "wa_train = np.zeros(nb_epoch)\n",
    "wa_test = np.zeros(nb_epoch)\n",
    "loss_train = np.zeros(nb_epoch)\n",
    "loss_test = np.zeros(nb_epoch)\n",
    "\n",
    "for epoch in range(nb_epoch):\n",
    "    epoch_time0 = time.time()\n",
    "    \n",
    "    total_ctcloss = 0.0\n",
    "    batches = range(0, X_train.shape[0], batch_size)\n",
    "    shuffle = np.random.choice(batches, size=len(batches), replace=False)\n",
    "    for num, i in enumerate(shuffle):\n",
    "        inputs_train = {'the_input': X_train[i:i+batch_size],\n",
    "                        'the_labels': y_train[i:i+batch_size],\n",
    "                        'input_length': np.sum(X_train_mask[i:i+batch_size], axis=1, dtype=np.int32),\n",
    "                        'label_length': np.squeeze(y_train_mask[i:i+batch_size]),\n",
    "                       }\n",
    "        outputs_train = {'ctc': np.zeros([inputs_train[\"the_labels\"].shape[0]])}\n",
    "\n",
    "        ctcloss = model.train_on_batch(x=inputs_train, y=outputs_train, \n",
    "                                       sample_weight=sample_weight[i:i+batch_size])\n",
    "\n",
    "        total_ctcloss += ctcloss * inputs_train[\"the_input\"].shape[0] * 1.\n",
    "    loss_train[epoch] = total_ctcloss / X_train.shape[0]\n",
    "\n",
    "    inputs_train = {'the_input': X_train,\n",
    "                    'the_labels': y_train,\n",
    "                    'input_length': np.sum(X_train_mask, axis=1, dtype=np.int32),\n",
    "                    'label_length': np.squeeze(y_train_mask),\n",
    "                   }\n",
    "    outputs_train = {'ctc': np.zeros([y_train.shape[0]])}\n",
    "    preds = test_func([inputs_train[\"the_input\"]])[0]\n",
    "    decode_function = K.ctc_decode(preds[:,2:,:], inputs_train[\"input_length\"]-2, greedy=False, top_paths=1)\n",
    "    labellings = decode_function[0][0].eval(session=sess)\n",
    "    if labellings.shape[1] == 0:\n",
    "        ua_train[epoch] = 0.0\n",
    "        wa_train[epoch] = 0.0\n",
    "    else:\n",
    "        ua_train[epoch] = unweighted_accuracy(y_train.ravel(), labellings.T[0].ravel())\n",
    "        wa_train[epoch] = weighted_accuracy(y_train.ravel(), labellings.T[0].ravel())\n",
    "\n",
    "\n",
    "    inputs_test = {'the_input': X_test,\n",
    "                   'the_labels': y_test,\n",
    "                   'input_length': np.sum(X_test_mask, axis=1, dtype=np.int32),\n",
    "                   'label_length': np.squeeze(y_test_mask),\n",
    "                  }\n",
    "    outputs_test = {'ctc': np.zeros([y_test.shape[0]])}\n",
    "    preds = test_func([inputs_test[\"the_input\"]])[0]\n",
    "    decode_function = K.ctc_decode(preds[:,2:,:], inputs_test[\"input_length\"]-2, greedy=False, top_paths=1)\n",
    "    labellings = decode_function[0][0].eval(session=sess)\n",
    "    if labellings.shape[1] == 0:\n",
    "        ua_test[epoch] = 0.0\n",
    "        wa_test[epoch] = 0.0\n",
    "    else:\n",
    "        ua_test[epoch] = unweighted_accuracy(y_test.ravel(), labellings.T[0].ravel())\n",
    "        wa_test[epoch] = weighted_accuracy(y_test.ravel(), labellings.T[0].ravel())\n",
    "    loss_test[epoch] = np.mean(model.predict(inputs_test))\n",
    "\n",
    "    epoch_time1 = time.time()\n",
    "\n",
    "\n",
    "    print('epoch = %d, \\\n",
    "WA Tr = %0.2f, UA Tr = %0.2f, WA Te = %0.2f, UA Te = %0.2f, CTC Tr = %0.2f, CTC Te = %0.2f, \\\n",
    "time = %0.2fmins' % (epoch + 1, \n",
    "                     wa_train[epoch], ua_train[epoch], \n",
    "                     wa_test[epoch], ua_test[epoch], \n",
    "                     loss_train[epoch], loss_test[epoch],\n",
    "                     (epoch_time1-epoch_time0)/60))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
